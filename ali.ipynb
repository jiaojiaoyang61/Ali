{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Failure Prediction</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried three models: logistic regression, Kmeans and NeuroNetwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Dropout\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas.plotting import andrews_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>device</th>\n",
       "      <th>failure</th>\n",
       "      <th>metric1</th>\n",
       "      <th>metric2</th>\n",
       "      <th>metric3</th>\n",
       "      <th>metric4</th>\n",
       "      <th>metric5</th>\n",
       "      <th>metric6</th>\n",
       "      <th>metric7</th>\n",
       "      <th>metric8</th>\n",
       "      <th>metric9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/15</td>\n",
       "      <td>S1F01085</td>\n",
       "      <td>0</td>\n",
       "      <td>215630672</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/15</td>\n",
       "      <td>S1F0166B</td>\n",
       "      <td>0</td>\n",
       "      <td>61370680</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>403174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/15</td>\n",
       "      <td>S1F01E6Y</td>\n",
       "      <td>0</td>\n",
       "      <td>173295968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>237394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/15</td>\n",
       "      <td>S1F01JE0</td>\n",
       "      <td>0</td>\n",
       "      <td>79694024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>410186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/15</td>\n",
       "      <td>S1F01R2B</td>\n",
       "      <td>0</td>\n",
       "      <td>135970480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>313173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date    device  failure    metric1  metric2  metric3  metric4  metric5  \\\n",
       "0  1/1/15  S1F01085        0  215630672       56        0       52        6   \n",
       "1  1/1/15  S1F0166B        0   61370680        0        3        0        6   \n",
       "2  1/1/15  S1F01E6Y        0  173295968        0        0        0       12   \n",
       "3  1/1/15  S1F01JE0        0   79694024        0        0        0        6   \n",
       "4  1/1/15  S1F01R2B        0  135970480        0        0        0       15   \n",
       "\n",
       "   metric6  metric7  metric8  metric9  \n",
       "0   407438        0        0        7  \n",
       "1   403174        0        0        0  \n",
       "2   237394        0        0        0  \n",
       "3   410186        0        0        0  \n",
       "4   313173        0        0        3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file to a dataframe\n",
    "df = pd.read_csv('predictive_maintenance_case.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "In this part, I turned the 'date' and 'device' column into int, checked the correlation and select features. And then I scaled the values and split them into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>failure</th>\n",
       "      <th>metric1</th>\n",
       "      <th>metric2</th>\n",
       "      <th>metric3</th>\n",
       "      <th>metric4</th>\n",
       "      <th>metric5</th>\n",
       "      <th>metric6</th>\n",
       "      <th>metric7</th>\n",
       "      <th>metric8</th>\n",
       "      <th>...</th>\n",
       "      <th>device_Z1F1HSWK</th>\n",
       "      <th>device_Z1F1Q9BD</th>\n",
       "      <th>device_Z1F1R76A</th>\n",
       "      <th>device_Z1F1RE71</th>\n",
       "      <th>device_Z1F1RJFA</th>\n",
       "      <th>device_Z1F1VMZB</th>\n",
       "      <th>device_Z1F1VQFY</th>\n",
       "      <th>device_Z1F26YZB</th>\n",
       "      <th>device_Z1F282ZV</th>\n",
       "      <th>device_Z1F2PBHX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215630672</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>407438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61370680</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>403174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173295968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>237394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79694024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>410186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135970480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>313173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  failure    metric1  metric2  metric3  metric4  metric5  metric6  \\\n",
       "0     0        0  215630672       56        0       52        6   407438   \n",
       "1     0        0   61370680        0        3        0        6   403174   \n",
       "2     0        0  173295968        0        0        0       12   237394   \n",
       "3     0        0   79694024        0        0        0        6   410186   \n",
       "4     0        0  135970480        0        0        0       15   313173   \n",
       "\n",
       "   metric7  metric8       ...         device_Z1F1HSWK  device_Z1F1Q9BD  \\\n",
       "0        0        0       ...                       0                0   \n",
       "1        0        0       ...                       0                0   \n",
       "2        0        0       ...                       0                0   \n",
       "3        0        0       ...                       0                0   \n",
       "4        0        0       ...                       0                0   \n",
       "\n",
       "   device_Z1F1R76A  device_Z1F1RE71  device_Z1F1RJFA  device_Z1F1VMZB  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   device_Z1F1VQFY  device_Z1F26YZB  device_Z1F282ZV  device_Z1F2PBHX  \n",
       "0                0                0                0                0  \n",
       "1                0                0                0                0  \n",
       "2                0                0                0                0  \n",
       "3                0                0                0                0  \n",
       "4                0                0                0                0  \n",
       "\n",
       "[5 rows x 1180 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn 'date' into int\n",
    "days = lambda x : (pd.to_datetime(x)-pd.to_datetime('1/1/15')).dt.days\n",
    "df[['date']] = df[['date']].apply(days)\n",
    "# turn 'device' into onehot-vector\n",
    "df = df.join(pd.get_dummies(df.device,prefix='device'))\n",
    "df = df.drop('device',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date 0.0006265146007184932\n",
      "failure 1.0\n",
      "metric1 0.001983484281090146\n",
      "metric2 0.05290157991458708\n",
      "metric3 -0.0009484301869248991\n",
      "metric4 0.06739847485574071\n",
      "metric5 0.0022697308795808506\n",
      "metric6 -0.0005503238387569551\n",
      "metric7 0.11905458506084267\n",
      "metric9 0.0016215740167767306\n",
      "device_S1F01085 -0.00020266351485579264\n",
      "device_S1F013BB -0.0002026635148557925\n",
      "device_S1F01E6Y -0.0005733157039486517\n",
      "device_S1F01R2B -0.001236605646252956\n",
      "device_S1F01XDJ -0.0008521722352638513\n",
      "device_S1F023H2 0.021933358369154696\n",
      "device_S1F02A0J -0.0012476670671129762\n",
      "device_S1F02L38 -0.0007675183395772688\n",
      "device_S1F03RV3 -0.00018500488805468844\n",
      "device_S1F03YZM 0.005418483483036847\n",
      "device_S1F044ET -0.0012722062126517737\n",
      "device_S1F04DH8 -0.00041371674039145204\n",
      "device_S1F04KSC -0.00016547273773747547\n",
      "device_S1F06ZX2 -0.0008759794815026017\n",
      "device_S1F09DZQ 0.0057256526279989475\n",
      "device_S1F0AADQ -0.0013634754696388322\n",
      "device_S1F0BVK1 -0.0012421485805738522\n",
      "device_S1F0BWZ3 -0.0013834987463145522\n",
      "device_S1F0C95J -0.0014032388574968665\n",
      "device_S1F0CE60 -0.0007585351109380966\n",
      "device_S1F0CSBR -0.00018500488805468847\n",
      "device_S1F0CTDN 0.036508923772597415\n",
      "device_S1F0CVWK -0.0013934034413487179\n",
      "device_S1F0DKAN -0.000986464532197911\n",
      "device_S1F0DSTY 0.013932757576284498\n",
      "device_S1F0E9EP -0.0014442991924044747\n",
      "device_S1F0EEP2 -0.0010698901731386783\n",
      "device_S1F0F4EB 0.007693988768340768\n",
      "device_S1F0F4G4 -0.0008109472541448344\n",
      "device_S1F0FW8K -0.001239380189853798\n",
      "device_S1F0FZ8F -0.0013685085123276884\n",
      "device_S1F0G9ZF -0.0012393801898537978\n",
      "device_S1F0GG8X 0.02255379530578567\n",
      "device_S1F0GJW3 0.01042807528743724\n",
      "device_S1F0GKFX 0.00809225339450738\n",
      "device_S1F0GKL6 0.0074755515285491216\n",
      "device_S1F0GPFZ 0.00560667713874517\n",
      "device_S1F0GSD9 0.00698495965999014\n",
      "device_S1F0H6JJ -0.0008151632719401698\n",
      "device_S1F0HWXJ -0.0004219116413208795\n",
      "device_S1F0J5JH 0.005849591048030377\n",
      "device_S1F0JD7P 0.008946303280285358\n",
      "device_S1F0JGJV 0.0044533733460561265\n",
      "device_S1F0JMRJ -0.0012962843603157009\n",
      "device_S1F0KZJJ -0.0008151632719401696\n",
      "device_S1F0L0DW 0.007204844104480732\n",
      "device_S1F0LBMG -0.0012449108594619006\n",
      "device_S1F0LCTV 0.018636676121596956\n",
      "device_S1F0LCVC 0.008050303632455742\n",
      "device_S1F0LD15 0.0056854606219847465\n",
      "device_S1F0LDB5 -0.00020266351485579256\n",
      "device_S1F0P3G2 0.021359577601178355\n",
      "device_S1F0PF59 -0.0010634557945446326\n",
      "device_S1F0PJJW 0.011906594906809218\n",
      "device_S1F0PLEL -0.000767518339577269\n",
      "device_S1F0PXZL -0.00021890249401437784\n",
      "device_S1F0QWGA -0.0008024489752227428\n",
      "device_S1F0QXRG -0.0002866163984754745\n",
      "device_S1F0QY0Q -0.001179755112369689\n",
      "device_S1F0QY11 0.02193335836915469\n",
      "device_S1F0QY8S -0.0002026635148557927\n",
      "device_S1F0QYLA -0.0006081077927691366\n",
      "device_S1F0QYX4 -0.0005298499937264425\n",
      "device_S1F0QZXV -0.0002482140912753358\n",
      "device_S1F0R12Y -0.000687439385872084\n",
      "device_S1F0R3JV -0.0012170080136393242\n",
      "device_S1F0R4JY -0.0002189024940143778\n",
      "device_S1F0R4Q8 -0.000965375515840633\n",
      "device_S1F0RM77 -0.00125863198175486\n",
      "device_S1F0RQLR -0.0012829629705497837\n",
      "device_S1F0RR35 0.00964938463482193\n",
      "device_S1F0RRB1 0.043271596118512015\n",
      "device_S1F0RRDW -0.00029832100404988455\n",
      "device_S1F0RREN -0.001261358426747258\n",
      "device_S1F0RS72 -0.0007585351109380965\n",
      "device_S1F0RSZP 0.008355022498302443\n",
      "device_S1F0RVVR -0.0009067540670808377\n",
      "device_S1F0S2WJ 0.021933358369154693\n",
      "device_S1F0S30R -0.0009105280309754844\n",
      "device_S1F0S33G -0.0007585351109380967\n",
      "device_S1F0S4CA 0.01213177621628486\n",
      "device_S1F0S4EG 0.005807703799377119\n",
      "device_S1F0S4T6 0.009847155601228055\n",
      "device_S1F0S561 -0.0011412950629066257\n",
      "device_S1F0S5B2 -0.00084001651186611\n",
      "device_S1F0S65X 0.005913540466462661\n",
      "device_S1F0S66R -0.000951057570308467\n",
      "device_S1F0S7DN -0.0009142864772620996\n",
      "device_S1F0SAC1 -0.0007119253402980783\n",
      "device_S1F0SBBW -0.0006924056940266103\n",
      "device_S1F0T2LA 0.005626176948278581\n",
      "device_S1F0TBK9 -0.0010952517617949286\n",
      "device_S1F0TP5E -0.001107716024780521\n",
      "device_S1F0TP8F -0.0013015750384467086\n",
      "device_S1F0TQCV 0.013304896562220518\n",
      "device_S1F0X4RC -0.0014154379035056872\n",
      "device_S1F100R5 -0.0014227075905053422\n",
      "device_S1F1021H -0.0007494445064325998\n",
      "device_S1F10BNL -0.0012962843603157006\n",
      "device_S1F10FF0 -0.001422707590505342\n",
      "device_S1F10GSG -0.0012613584267472577\n",
      "device_S1F10HH5 -0.0011108103619046125\n",
      "device_S1F10RWZ -0.0012775958259389306\n",
      "device_S1F11KQW -0.0011768409899795675\n",
      "device_S1F11L11 -0.0008521722352638514\n",
      "device_S1F11MB0 0.03650892377259741\n",
      "device_S1F12XJ4 -0.0007262216470457396\n",
      "device_S1F13589 0.007770041593182898\n",
      "device_S1F135BR -0.0012962843603157004\n",
      "device_S1F135DN -0.0008521722352638512\n",
      "device_S1F135TN 0.005492316556161965\n",
      "device_S1F135WP -0.0014154379035056874\n",
      "device_S1F1360P -0.0010762862908389684\n",
      "device_S1F1360W -0.001017282311707293\n",
      "device_S1F136J0 0.007731803431198764\n",
      "device_S1F13H80 0.008541628404754658\n",
      "device_S1F13KBJ -0.0010983810124547103\n",
      "device_W1F00CL9 -0.0012421485805738524\n",
      "device_W1F03D4L 0.007770041593182899\n",
      "device_W1F03DP4 0.025661641632581025\n",
      "device_W1F05X69 -0.001444299192404475\n",
      "device_W1F06QVP -0.0006874393858720843\n",
      "device_W1F08EDA 0.012881128915257618\n",
      "device_W1F0976M -0.0013277147314455424\n",
      "device_W1F0F65G -0.0007402425701448076\n",
      "device_W1F0F6BN 0.02033044032274517\n",
      "device_W1F0FKWW 0.009054797472751484\n",
      "device_W1F0FW0S 0.017927620334926227\n",
      "device_W1F0G99N -0.0003700320698391664\n",
      "device_W1F0GCAZ 0.0064034047603894915\n",
      "device_W1F0HJWZ -0.0012393801898537976\n",
      "device_W1F0HPZK -0.0012449108594619009\n",
      "device_W1F0KCP2 0.007546804880156963\n",
      "device_W1F0KD2K -0.00046070656895335753\n",
      "device_W1F0KD36 -0.001113896152753323\n",
      "device_W1F0M492 -0.0006568552405688265\n",
      "device_W1F0M4BZ 0.0065856343669633945\n",
      "device_W1F0MNDQ -0.0011621614887202599\n",
      "device_W1F0N84F -0.001376023861176974\n",
      "device_W1F0NZSK -0.0008151632719401695\n",
      "device_W1F0NZZZ 0.014843042488413742\n",
      "device_W1F0P114 0.019866389717963236\n",
      "device_W1F0PAXH 0.005870756480292796\n",
      "device_W1F0PNA5 0.032142944272699155\n",
      "device_W1F0Q8FH 0.0102748549049309\n",
      "device_W1F0QTJM -0.0001850048880546885\n",
      "device_W1F0SGHR 0.016442022006608575\n",
      "device_W1F0T034 0.0232276382510903\n",
      "device_W1F0T074 0.014843042488413748\n",
      "device_W1F0T0B1 0.004193900774104413\n",
      "device_W1F0TA59 0.015937494838573575\n",
      "device_W1F0TCG0 -0.0011108103619046122\n",
      "device_W1F0TYQ9 -0.0009582431704259787\n",
      "device_W1F0VAS7 -0.0007981660087831685\n",
      "device_W1F0VFRE -0.0008067092712441122\n",
      "device_W1F0VJT2 -0.0006568552405688264\n",
      "device_W1F0VZF4 -0.001079470214551822\n",
      "device_W1F0W9SR -0.0003606611998324425\n",
      "device_W1F0WBTM 0.007204844104480734\n",
      "device_W1F0WJFT -0.0001433030189552076\n",
      "device_W1F0WKE1 -0.0011970918522337859\n",
      "device_W1F0X4F6 -0.00036066119983244255\n",
      "device_W1F0X4FC 0.019866389717963246\n",
      "device_W1F0X5GW 0.020330440322745162\n",
      "device_W1F0X6CF -0.0006081077927691365\n",
      "device_W1F0Z1W9 0.021933358369154686\n",
      "device_W1F0Z3G1 -0.0012282446807210352\n",
      "device_W1F0Z3KR 0.009400374128921855\n",
      "device_W1F0Z4EA 0.018636676121596953\n",
      "device_W1F0ZG5V -0.0008759794815026016\n",
      "device_W1F10Y8K -0.0014154379035056877\n",
      "device_W1F11ZG9 0.005173924297606187\n",
      "device_W1F1230J 0.025661641632581035\n",
      "device_W1F13SRV 0.02665318485820438\n",
      "device_W1F14FS4 -0.001393403441348718\n",
      "device_W1F14XGD 0.005529944035280565\n",
      "device_W1F19BPT 0.011588508089676082\n",
      "device_W1F1B0KF -0.0013685085123276886\n",
      "device_W1F1BFP5 0.005685460621984745\n",
      "device_W1F1BFZT -0.0007494445064326\n",
      "device_W1F1BRM3 -0.0014227075905053424\n",
      "device_W1F1BS0H 0.005913540466462662\n",
      "device_W1F1BZTM 0.00796788750738157\n",
      "device_W1F1C9TE 0.01261791798518349\n",
      "device_W1F1C9WG 0.007693988768340769\n",
      "device_W1F1CB5E 0.005400313599306777\n",
      "device_W1F1CDDP 0.009281655364462097\n",
      "device_W1F1CJ1K 0.005828574110104121\n",
      "device_W1F1CJXM -0.0006773977915152273\n",
      "device_W1F1CMCY -0.0012909721714134388\n",
      "device_W1F1DA55 -0.0012936309712486328\n",
      "device_W1F1DA5ÿ -8.273537198296135e-05\n",
      "device_W1F1DPSA -0.0011200423779804127\n",
      "device_W1F1DQJD -0.0012722062126517733\n",
      "device_W1F1DQN8 0.005473682601578184\n",
      "device_W1F1FHEK -0.001296284360315701\n",
      "device_Z1F04GCH 0.013159525683127464\n",
      "device_Z1F0AM4J -0.0009864645321979108\n",
      "device_Z1F0B4XZ 0.00805030363245574\n",
      "device_Z1F0CBSH -0.0006137150572814228\n",
      "device_Z1F0E1CS -0.0009829809762439221\n",
      "device_Z1F0FSBY 0.010274854904930898\n",
      "device_Z1F0K451 0.007546804880156964\n",
      "device_Z1F0L4T5 -0.0013934034413487176\n",
      "device_Z1F0LSNZ 0.006207437826424144\n",
      "device_Z1F0LVGY 0.015937494838573568\n",
      "device_Z1F0M7QD -0.00024821409127533567\n",
      "device_Z1F0MRPJ 0.005157224723334745\n",
      "device_Z1F0N11J -0.0003968199689682968\n",
      "device_Z1F0P16F 0.005935162927146307\n",
      "device_Z1F0P5D9 0.01570085379913782\n",
      "device_Z1F0Q9H0 -0.0008400165118661099\n",
      "device_Z1F0QH0C 0.009915342774982605\n",
      "device_Z1F0VJ8V -0.0007585351109380968\n",
      "device_Z1F130LH 0.01148731808860943\n",
      "device_Z1F148T1 0.008400772177073206\n",
      "device_Z1F14BGY 0.004402017973079199\n",
      "device_Z1F1653X 0.007656589429799076\n",
      "device_Z1F16BR1 -0.000707095830606693\n",
      "device_Z1F17ZCN -0.0012722062126517735\n",
      "device_Z1F1901P 0.007510989396385521\n",
      "device_Z1F1Q9BD -0.0007494445064325999\n",
      "device_Z1F1RJFA 0.007808711657988718\n",
      "device_Z1F2PBHX -0.0007540034723265887\n"
     ]
    }
   ],
   "source": [
    "# check correlation and delete redundant features\n",
    "temp=[]\n",
    "columns=[]\n",
    "for column in df.columns.values.tolist():\n",
    "    pearson_coef, p_value = stats.pearsonr(df[column], df['failure'])\n",
    "    temp.append(pearson_coef)\n",
    "    if pearson_coef not in temp[:-1]:\n",
    "        print(column,pearson_coef)\n",
    "        columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose features: There is no feature shows high relavance with 'failure', so I choose the following features. \n",
    "columns=['date','failure','metric1','metric2','metric3','metric4','metric5','metric6','metric7','metric9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 8.83223757e-01 8.61962812e-04 ... 5.91208731e-01\n",
      "  0.00000000e+00 3.74311534e-04]\n",
      " [0.00000000e+00 2.51374455e-01 0.00000000e+00 ... 5.85021497e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.09820707e-01 0.00000000e+00 ... 3.44468129e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 7.79433218e-02 7.43750770e-02 ... 5.08458836e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.29601711e-01 0.00000000e+00 ... 5.20894247e-01\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 7.19783954e-02 0.00000000e+00 ... 5.09940348e-01\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Train set: (99595, 9) (99595,)\n",
      "Test set: (24899, 9) (24899,)\n"
     ]
    }
   ],
   "source": [
    "# normalize and split the dataset\n",
    "X = df[columns]\n",
    "X = X.drop(['failure'],axis=1).values\n",
    "y = df[['failure']].values\n",
    "y = y.reshape(1,len(y))[0]\n",
    "\n",
    "# normalize data\n",
    "# X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "# print(X[0:5])\n",
    "X = preprocessing.maxabs_scale(X)\n",
    "print(X)\n",
    "\n",
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2) #random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "These two functions are used to compute precision, recall, f1-score, TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision and recall\n",
    "def cal_p_r(y_test,yhat):\n",
    "     print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute TP, TN, FP, FN\n",
    "def cal_base(y_true, y_pred):\n",
    "    y_pred_positive = np.round(np.clip(y_pred, 0, 1))\n",
    "    y_pred_negative = 1 - y_pred_positive\n",
    "\n",
    "    y_positive = np.round(np.clip(y_true, 0, 1))\n",
    "    y_negative = 1 - y_positive\n",
    "\n",
    "    TP = np.sum(y_positive * y_pred_positive)\n",
    "    TN = np.sum(y_negative * y_pred_negative)\n",
    "\n",
    "    FP = np.sum(y_negative * y_pred_positive)\n",
    "    FN = np.sum(y_positive * y_pred_negative)\n",
    "\n",
    "    print('TP={}, TN={}, FP={}, FN={}'.format(TP, TN, FP, FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "### 1.logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python37/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "LR = LogisticRegression(penalty='l2',C=0.1, solver='saga',class_weight='balanced')\n",
    "# train the model\n",
    "LR.fit(X_train,y_train)\n",
    "# prediction\n",
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64     24882\n",
      "           1       0.00      0.59      0.00        17\n",
      "\n",
      "   micro avg       0.47      0.47      0.47     24899\n",
      "   macro avg       0.50      0.53      0.32     24899\n",
      "weighted avg       1.00      0.47      0.64     24899\n",
      "\n",
      "TP=10, TN=11666, FP=13216, FN=7\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "cal_p_r(y_test, yhat)\n",
    "cal_base(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't performs well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "k_means = KMeans( n_clusters = 2, n_init = 12)\n",
    "# train\n",
    "k_means.fit(X_train)\n",
    "# prediction\n",
    "result = k_means.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67     24882\n",
      "           1       0.00      0.41      0.00        17\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     24899\n",
      "   macro avg       0.50      0.46      0.33     24899\n",
      "weighted avg       1.00      0.50      0.66     24899\n",
      "\n",
      "TP=7, TN=12401, FP=12481, FN=10\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "cal_p_r(y_test, result)\n",
    "cal_base(y_test, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model doesn't performs well either. There are too many FP and FN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neuro Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=9, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python37/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the label to 2 dimentions.\n",
    "ohe = OneHotEncoder()\n",
    "y_train = y_train.reshape(len(y_train),1)\n",
    "y_test = y_test.reshape(len(y_test),1)\n",
    "\n",
    "y_train_1=ohe.fit_transform(y_train).toarray()\n",
    "y_test_1=ohe.fit_transform(y_test).toarray()\n",
    "\n",
    "y_train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99595 samples, validate on 24899 samples\n",
      "Epoch 1/20\n",
      "99595/99595 [==============================] - 0s 4us/step - loss: 0.6759 - acc: 0.9610 - val_loss: 0.5092 - val_acc: 0.9894\n",
      "Epoch 2/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6525 - acc: 0.9939 - val_loss: 0.4469 - val_acc: 0.9991\n",
      "Epoch 3/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6501 - acc: 0.9988 - val_loss: 0.4463 - val_acc: 0.9989\n",
      "Epoch 4/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6446 - acc: 0.9985 - val_loss: 0.4102 - val_acc: 0.9989\n",
      "Epoch 5/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6503 - acc: 0.9986 - val_loss: 0.4499 - val_acc: 0.9987\n",
      "Epoch 6/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6422 - acc: 0.9982 - val_loss: 0.4396 - val_acc: 0.9984\n",
      "Epoch 7/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6485 - acc: 0.9979 - val_loss: 0.4321 - val_acc: 0.9983\n",
      "Epoch 8/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6438 - acc: 0.9977 - val_loss: 0.4410 - val_acc: 0.9980\n",
      "Epoch 9/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6345 - acc: 0.9977 - val_loss: 0.4488 - val_acc: 0.9979\n",
      "Epoch 10/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6340 - acc: 0.9975 - val_loss: 0.4081 - val_acc: 0.9979\n",
      "Epoch 11/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6268 - acc: 0.9976 - val_loss: 0.4250 - val_acc: 0.9977\n",
      "Epoch 12/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6144 - acc: 0.9974 - val_loss: 0.3990 - val_acc: 0.9979\n",
      "Epoch 13/20\n",
      "99595/99595 [==============================] - 0s 2us/step - loss: 0.6294 - acc: 0.9975 - val_loss: 0.4430 - val_acc: 0.9975\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# compute class weight and train the model\n",
    "neg = sum(y_train==0)[0] \n",
    "pos = sum(y_train==1)[0]\n",
    "total = len(y_train)\n",
    "weight_for_0 = (1 / neg)*(total)/2.0\n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max')\n",
    "#     restore_best_weights=True)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "history = model.fit(X_train, y_train_1, \n",
    "                    epochs=20, \n",
    "                    batch_size=1000, \n",
    "                    callbacks = [early_stopping], \n",
    "                    validation_data=(X_test, y_test_1),\n",
    "                    class_weight=class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test_1)):\n",
    "    test.append(np.argmax(y_test_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     24882\n",
      "           1       0.04      0.12      0.06        17\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     24899\n",
      "   macro avg       0.52      0.56      0.53     24899\n",
      "weighted avg       1.00      1.00      1.00     24899\n",
      "\n",
      "TP=2, TN=24835, FP=47, FN=15\n"
     ]
    }
   ],
   "source": [
    "cal_p_r(test, pred)\n",
    "cal_base(test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although FP decreased a lot, only 2 failure instances are predicted correct. This is not good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is extreamly unbalanced, I augmented (adding random noise) the failure class data and added them into the training and testing dataset. The result is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "89000\n",
      "(99595, 9) (89000, 9)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(188595, 9)\n",
      "<class 'numpy.ndarray'>\n",
      "17000\n",
      "(24899, 9) (17000, 9)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(41899, 9)\n"
     ]
    }
   ],
   "source": [
    "# add more data\n",
    "train_add=[]\n",
    "for jj in range(1000):\n",
    "    for ii,value in enumerate(y_train):\n",
    "        if value==1:\n",
    "            train_add.append((np.random.randn(9)*0.05+1)*X_train[ii])\n",
    "train_add=np.array(train_add)\n",
    "print(type(train_add))\n",
    "print(len(train_add))\n",
    "\n",
    "print(X_train.shape,train_add.shape)\n",
    "print(type(X_train),type(train_add))\n",
    "X_train=np.concatenate((X_train,train_add),axis=0)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "test_add=[]\n",
    "for jj in range(1000):\n",
    "    for ii,value in enumerate(y_test):\n",
    "        if value==1:\n",
    "            test_add.append((np.random.randn(9)*0.05+1)*X_test[ii])\n",
    "test_add=np.array(test_add)\n",
    "print(type(test_add))\n",
    "print(len(test_add))\n",
    "\n",
    "print(X_test.shape,test_add.shape)\n",
    "print(type(X_test),type(test_add))\n",
    "X_test=np.concatenate((X_test,test_add),axis=0)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_train=np.concatenate((y_train,np.array([[1]]*sum(y_train==1)[0]*1000)),axis=0)\n",
    "y_test=np.concatenate((y_test,np.array([[1]]*sum(y_test==1)[0]*1000)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python37/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/anaconda3/envs/python37/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "y_train_2=ohe.fit_transform(y_train).toarray()\n",
    "y_test_2=ohe.fit_transform(y_test).toarray()\n",
    "y_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 188595 samples, validate on 41899 samples\n",
      "Epoch 1/20\n",
      "188595/188595 [==============================] - 1s 3us/step - loss: 0.6889 - acc: 0.5440 - val_loss: 0.6707 - val_acc: 0.6482\n",
      "Epoch 2/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.6635 - acc: 0.6179 - val_loss: 0.6413 - val_acc: 0.6590\n",
      "Epoch 3/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.6303 - acc: 0.6465 - val_loss: 0.6017 - val_acc: 0.6785\n",
      "Epoch 4/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.5887 - acc: 0.7005 - val_loss: 0.5392 - val_acc: 0.7669\n",
      "Epoch 5/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.5435 - acc: 0.7430 - val_loss: 0.4912 - val_acc: 0.7736\n",
      "Epoch 6/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.5046 - acc: 0.7661 - val_loss: 0.4648 - val_acc: 0.7930\n",
      "Epoch 7/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.4773 - acc: 0.7779 - val_loss: 0.4422 - val_acc: 0.8117\n",
      "Epoch 8/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.4547 - acc: 0.7907 - val_loss: 0.4091 - val_acc: 0.8220\n",
      "Epoch 9/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.4355 - acc: 0.8057 - val_loss: 0.3866 - val_acc: 0.8274\n",
      "Epoch 10/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.4219 - acc: 0.8167 - val_loss: 0.3824 - val_acc: 0.8172\n",
      "Epoch 11/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.4113 - acc: 0.8272 - val_loss: 0.3679 - val_acc: 0.8288\n",
      "Epoch 12/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.4025 - acc: 0.8333 - val_loss: 0.3585 - val_acc: 0.8362\n",
      "Epoch 13/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.3962 - acc: 0.8359 - val_loss: 0.3540 - val_acc: 0.8410\n",
      "Epoch 14/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.3905 - acc: 0.8383 - val_loss: 0.3508 - val_acc: 0.8542\n",
      "Epoch 15/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.3862 - acc: 0.8393 - val_loss: 0.3505 - val_acc: 0.8473\n",
      "Epoch 16/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.3826 - acc: 0.8409 - val_loss: 0.3455 - val_acc: 0.8500\n",
      "Epoch 17/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.3800 - acc: 0.8418 - val_loss: 0.3517 - val_acc: 0.8500\n",
      "Epoch 18/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.3777 - acc: 0.8422 - val_loss: 0.3387 - val_acc: 0.8498\n",
      "Epoch 19/20\n",
      "188595/188595 [==============================] - 0s 1us/step - loss: 0.3754 - acc: 0.8427 - val_loss: 0.3381 - val_acc: 0.8570\n",
      "Epoch 20/20\n",
      "188595/188595 [==============================] - 0s 2us/step - loss: 0.3733 - acc: 0.8436 - val_loss: 0.3418 - val_acc: 0.8553\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=9, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='acc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max')\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "history = model.fit(X_train, y_train_2, \n",
    "                    epochs=20, \n",
    "                    batch_size=1000, \n",
    "                    callbacks = [early_stopping], \n",
    "                    validation_data=(X_test, y_test_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test_2)):\n",
    "    test.append(np.argmax(y_test_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     24882\n",
      "           1       0.84      0.80      0.82     17017\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     41899\n",
      "   macro avg       0.85      0.85      0.85     41899\n",
      "weighted avg       0.85      0.86      0.85     41899\n",
      "\n",
      "TP=13639, TN=22199, FP=2683, FN=3378\n"
     ]
    }
   ],
   "source": [
    "cal_p_r(test, pred)\n",
    "cal_base(test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "From the precision, recall, TP, TN, FP, FN values we can see that \n",
    "1. Logistic regration and kmeans can not predict the failure well.\n",
    "2. Neural network is better than them.\n",
    "3. After adding augmented data, the nerual network performs better. If we assume that the future unseen failure data are similar to the augmented failure data, we can use this model to do the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
